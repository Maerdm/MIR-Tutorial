{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7eb07b96",
   "metadata": {},
   "source": [
    "### MIR-Libraries\n",
    "- https://essentia.upf.edu/\n",
    "- https://librosa.org/\n",
    "- https://madmom.readthedocs.io/en/latest/\n",
    "- https://www.audeering.com/research/opensmile/\n",
    "- ...\n",
    "- https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/13075/Moffatt%20AN%20EVALUATION%20OF%20AUDIO%20FEATURE%202015%20Published.pdf?sequence=2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67e4e9f9",
   "metadata": {},
   "source": [
    "### Installation\n",
    "- Essentia Mac/Linux: pip install oder homebrew formula\n",
    "- Essentia docker image to run a jupyter notebook: https://hub.docker.com/r/mtgupf/essentia/\n",
    "- Essentia Docker Image mit Librosa: https://github.com/Maerdm/MIR-toolbox-docker\n",
    "- docker pull maedd/mir-toolbox_librosa\n",
    "- Run the Image: docker run -d --name MIR_Tutorial -p 8888:8888 -e JUPYTER_TOKEN=\"mir\" --mount type=bind,source=$(pwd),target=/notebooks maedd/mir-toolbox_librosa\n",
    "- anaconda/jupyter: https://www.youtube.com/watch?v=tFVjzORFmdI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install essentia-tensorflow\n",
    "! pip install librosa\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia.standard as es\n",
    "import essentia\n",
    "import librosa\n",
    "import numpy as np\n",
    "import IPython\n",
    "from pylab import plot, show, figure, imshow\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c390781",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(es))\n",
    "help(es.MFCC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f4bf232",
   "metadata": {},
   "source": [
    "### Audio Laden:\n",
    "- AudioLoader (stereo) \n",
    "- MonoLoader (mono)\n",
    "- EasyLoader (mono, normalisiert)\n",
    "- EqloudLoader (mono, normalisiert, EqualLoudness Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440857a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "\n",
    "file = '../AudioFiles/DontStop.mp3'\n",
    "\n",
    "audio = es.MonoLoader(filename=file, sampleRate=sr)()\n",
    "y, sr = librosa.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3135428",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio('../AudioFiles/DontStop.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(audio[:1000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62cd9a9d",
   "metadata": {},
   "source": [
    "### Lowlevel Features zeitbereich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_essentia = es.ZeroCrossingRate()(audio)\n",
    "z_librosa = librosa.feature.zero_crossing_rate(audio)\n",
    "print(z_essentia)\n",
    "print(np.mean(z_librosa))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45aa1a5d",
   "metadata": {},
   "source": [
    "### Spektrum berechnen\n",
    "\n",
    "<img src=\"../Sonstiges/Bilder/FFT.png\" align=\"left\" width=\"450\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = es.Windowing(type='hann')\n",
    "spectrum = es.Spectrum()\n",
    "lin2db = es.UnaryOperator(type='lin2db')\n",
    " \n",
    "frame = audio[44100*2 : 44100*2+1024]\n",
    "\n",
    "spec = lin2db(spectrum(w(frame)))\n",
    "\n",
    "plot(spec)\n",
    "plt.title(\"The spectrum of a frame:\")\n",
    "show()\n",
    "\n",
    "imshow(np.array([spec]).T, aspect = 'auto', origin='lower')\n",
    "plt.title(\"Spectrum\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8933c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = es.Windowing(type='hann')\n",
    "spectrum = es.Spectrum()\n",
    "logNorm = es.UnaryOperator(type='lin2db') # logarithmic dB scale (log10(x) * 20)\n",
    "pool = essentia.Pool()\n",
    "\n",
    "frameSize=1024\n",
    "hopSize=512\n",
    "\n",
    "for frame in es.FrameGenerator(audio[:44100], frameSize=frameSize, hopSize=hopSize):\n",
    "    spec = logNorm(spectrum(w(frame)))\n",
    "    pool.add('spec', spec)\n",
    "\n",
    "imshow(pool['spec'].T, aspect = 'auto', origin='lower', interpolation='none')\n",
    "plt.title(\"Spectrum\")\n",
    "plt.show()\n",
    "\n",
    "# frequency resolution = frameSize/2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "999f3654",
   "metadata": {},
   "source": [
    "### Log Frequency Spektrum und Pitch Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ac331",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromatic = '../Audiofiles/chromaTones.mp3'\n",
    "chromatic_audio = es.MonoLoader(filename=chromatic, sampleRate=sr)()\n",
    "IPython.display.Audio(chromatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6450f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w = es.Windowing(type='hann')\n",
    "spectrum = es.Spectrum()\n",
    "logNorm = es.UnaryOperator(type='lin2db', scale=1) # logarithmic dB scale (log10(x) * 20)\n",
    "pool = essentia.Pool()\n",
    "spectrum_logfreq = es.LogSpectrum(binsPerSemitone=3, frameSize=frameSize)\n",
    "\n",
    "frameSize=1024\n",
    "hopSize=512\n",
    "\n",
    "for frame in es.FrameGenerator(chromatic_audio, frameSize=frameSize, hopSize=hopSize):\n",
    "    spec = spectrum(w(frame))\n",
    "    frame_spec, _, _  = spectrum_logfreq(spec) # logarithmic frequency axis\n",
    "    pool.add('spec', logNorm(spec))\n",
    "    pool.add('log_spec', logNorm(frame_spec))\n",
    "    \n",
    "\n",
    "imshow(pool['spec'].T[1:,:], aspect = 'auto', origin='lower', interpolation='none')\n",
    "plt.title(\"Spectrum\")\n",
    "show()\n",
    "\n",
    "imshow(pool['log_spec'].T, aspect = 'auto', origin='lower', interpolation='none')\n",
    "plt.title(\"Spectrum\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e37b031",
   "metadata": {},
   "source": [
    "#### Chromagram\n",
    "- Aufteilung in 12 Töne (C, C#, D, D#, ...), Oktaven werden zusammengefasst\n",
    "######\n",
    "- --> robuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62efdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = librosa.feature.chroma_stft(y=chromatic_audio)\n",
    "img = librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')\n",
    "# --> Essentia: HPCP Algorithm (https://essentia.upf.edu/tutorial_tonal_hpcpkeyscale.html) --> spectral Peaks als Input\n",
    "# --> Key(), ChordsDescriptors(), ChordsDetection()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25ff80fe",
   "metadata": {},
   "source": [
    "### Mel-Spektrogram und Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "\n",
    "##### Mel-Skala:\n",
    "<img src=\"../Sonstiges/Bilder/Mel_Scale.png\" align=\"left\" width=\"450\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff91aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = es.Windowing(type='hann')\n",
    "spectrum = es.Spectrum()\n",
    "\n",
    "mel = es.MelBands(numberBands=96)\n",
    "mfcc = es.MFCC(numberBands=96, numberCoefficients=13)\n",
    "logNorm = es.UnaryOperator(type='lin2db')\n",
    "\n",
    "frameSize=2048\n",
    "hopSize=512\n",
    "\n",
    "pool.clear()\n",
    "\n",
    "for frame in es.FrameGenerator(audio, frameSize=frameSize, hopSize=hopSize, startFromZero=False):\n",
    "    spec = spectrum(w(frame))\n",
    "    melspec = logNorm(mel(spec))\n",
    "    bands, coeffs = mfcc(spec)\n",
    "\n",
    "    pool.add('mel', melspec)\n",
    "    pool.add('mfccs', coeffs)\n",
    "\n",
    "imshow(pool['mel'].T, aspect = 'auto', origin='lower', interpolation='none')\n",
    "plt.title(\"Mel\")\n",
    "show()\n",
    "\n",
    "imshow(pool['mfccs'].T[1:,:], aspect = 'auto', origin='lower', interpolation='none')\n",
    "plt.title(\"MFCCs\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe774b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram\n",
    "spec_lib = librosa.power_to_db(np.abs(librosa.stft(audio, n_fft=frameSize, hop_length=hopSize, window='hann')))\n",
    "\n",
    "# mel spectrogram\n",
    "mel_lib = librosa.feature.melspectrogram(y=audio, n_fft=frameSize, hop_length=hopSize, sr=sr, \n",
    "                                         center=False,n_mels=96)\n",
    "mel_lib = librosa.power_to_db(mel_lib)\n",
    "\n",
    "# mfccs\n",
    "mfccs = librosa.feature.mfcc(y=audio, n_fft=frameSize, hop_length=hopSize, sr=sr, n_mfcc=13)\n",
    "\n",
    "imshow(spec_lib, aspect = 'auto', origin='lower', interpolation='none')\n",
    "show()\n",
    "\n",
    "imshow(mel_lib, aspect = 'auto', origin='lower', interpolation='none')\n",
    "show()\n",
    "\n",
    "imshow(mfccs, aspect = 'auto', origin='lower', interpolation='none')\n",
    "show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c07601ad",
   "metadata": {},
   "source": [
    "### Lowlevel Features (Spectral)\n",
    "- Spectral Centroid: Frequenz, die die spektrale Energie in zwei gleich große Teile teilt \n",
    "######\n",
    "- Spectral Rolloff: Grenzfrequenz, unterhalb derer sich die maßgebliche spektrale Energie befindet (oft 85%)\n",
    "######\n",
    "- Spectral Flux: Stärke der spektralen Änderungen (Summe der Differenzen aufeinanderfolgender Betragsspektren)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = es.Windowing(type='hann')\n",
    "spectrum = es.Spectrum()\n",
    "centroid = es.Centroid(range=22050)\n",
    "flux = es.Flux()\n",
    "rolloff = es.RollOff()\n",
    "rms = es.RMS()\n",
    "\n",
    "pool = essentia.Pool()\n",
    "\n",
    "frameSize = 1024\n",
    "hopSize = 512\n",
    "\n",
    "pool.clear()\n",
    "\n",
    "for frame in es.FrameGenerator(audio, frameSize=frameSize, hopSize=hopSize, startFromZero=False):  \n",
    "    pool.add('centroid', centroid(spectrum(w(frame))))\n",
    "    pool.add('flux', flux(spectrum(frame)))\n",
    "    pool.add('rolloff', rolloff(spectrum(w(frame))))\n",
    "    pool.add('rms', rms(w(frame)))\n",
    "        \n",
    "#cent_lib = librosa.feature.spectral_centroid(y=audio, n_fft=frameSize, hop_length=hopSize, sr=sr)\n",
    "\n",
    "fig, ax = plt.subplots(4, 1, sharex=True, sharey=False, figsize=(15, 16))\n",
    "ax[0].set_title(\"spectral centroid\")\n",
    "ax[0].plot(pool['centroid'].T)\n",
    "ax[1].set_title(\"flux\")\n",
    "ax[1].plot(pool['flux'])\n",
    "ax[2].set_title(\"rolloff\")\n",
    "ax[2].plot(pool['rolloff'])\n",
    "ax[3].set_title(\"rms\")\n",
    "ax[3].plot(pool['rms'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "958d6337",
   "metadata": {},
   "source": [
    "### Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebd5491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Als JSON-Datei speichern\n",
    "statistics = es.PoolAggregator(defaultStats = [ 'mean', 'stdev' ])(pool)\n",
    "# --> https://essentia.upf.edu/reference/std_PoolAggregator.html\n",
    "\n",
    "es.YamlOutput(filename = '../AudioFiles/' + 'features.json', format='json')(statistics)\n",
    "es.YamlOutput(filename = '../AudioFiles/' + 'features_frames.json', format='json')(pool)\n",
    "\n",
    "# pool.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dff13e2b",
   "metadata": {},
   "source": [
    "### Onset Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17c9d80f",
   "metadata": {},
   "source": [
    "<img src=\"../Sonstiges/Bilder/onset.png\" align=\"left\" width=\"450\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b301a85",
   "metadata": {},
   "source": [
    "\n",
    "1. Novelty Function berechnen:\n",
    "    - https://essentia.upf.edu/reference/std_OnsetDetection.html\n",
    "###\n",
    "2. Peak Picking/Detect Onsets:\n",
    "    - https://essentia.upf.edu/reference/std_Onsets.html\n",
    "    - --> als Input auch mehrere novelty functions möglich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(es.Onsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onset Detection kann mehrere novelty functions berechnen\n",
    "o_hfc = es.OnsetDetection(method='hfc') # spectral based novelty (HFC = High Frequency Content of a spectrum)   \n",
    "o_rms = es.OnsetDetection(method='rms') # energy based novelty\n",
    "onsets = es.Onsets() # Computes onset positions/preprocesses Novelty function, Argumente: alpha = 0.001, delay=2\n",
    "\n",
    "w = es.Windowing(type='hann')\n",
    "fft = es.FFT()\n",
    "c2p = es.CartesianToPolar()\n",
    "pool = essentia.Pool()\n",
    "\n",
    "# Compute HFC and RMS novelty functions\n",
    "for frame in es.FrameGenerator(audio, frameSize=1024, hopSize=512):\n",
    "    magnitude, phase = c2p(fft(w(frame)))\n",
    "    pool.add('hfc', o_hfc(magnitude, phase))\n",
    "    pool.add('rms', o_rms(magnitude, phase))\n",
    "\n",
    "# Peak Pickng/selecting onsets\n",
    "onsets_hfc = onsets(essentia.array([pool['hfc']]), [1])\n",
    "onsets_rms = onsets(essentia.array([pool['rms']]), [1])\n",
    " \n",
    "# Plotting\n",
    "n_frames = len(pool['hfc'])\n",
    "frames_position_samples = np.array(range(n_frames)) * 512\n",
    "fig, ax = plt.subplots(3, 1, sharex=True, sharey=False, figsize=(15, 8))\n",
    "ax[0].set_title(\"hfc novelty function\")\n",
    "ax[0].plot(frames_position_samples, pool['hfc'].T)\n",
    "ax[1].set_title(\"rms novelty function\")\n",
    "ax[1].plot(frames_position_samples, pool['rms'].T)\n",
    "ax[2].set_title(\"onsets and waveform\")\n",
    "ax[2].plot(audio)\n",
    "for onset in onsets_hfc:\n",
    "    ax[2].axvline(x=onset*44100, color='magenta')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44e13453",
   "metadata": {},
   "source": [
    "### Essentia Extractors\n",
    "\n",
    "- Extractor: alle low/mid/high level \n",
    "- MusicExtractor: https://acousticbrainz.org/\n",
    "- FreesoundExtractor: https://freesound.org/\n",
    "- LowLevelSpectralEqloudExtractor: Spectral Features für die Equal Loudness nötig ist\n",
    "- LowLevelSpectralExtractor: Spectral Features, für die keine Equal Loudness nötig ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Music Extractor\n",
    "pool = essentia.Pool()\n",
    "extractor = es.Extractor()(audio)\n",
    "\n",
    "#aggrpool = es.PoolAggregator(defaultStats = ['mean', 'stdev', 'min', 'max'])(extractor) # 'stdev', 'min', 'max', 'median'\n",
    "es.YamlOutput(filename = '../AudioFiles/' + 'features.yaml', format='json')(extractor)\n",
    "\n",
    "# extractor['lowLevel.spectral_centroid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pool.descriptorNames())\n",
    "pool.clear()\n",
    "help(es.Extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, features_frames = es.MusicExtractor(lowlevelStats=[\"mean\"], rhythmStats=[\"mean\"], tonalStats=[\"mean\"])(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69a234c1",
   "metadata": {},
   "source": [
    "### ML Models\n",
    "\n",
    "--> https://essentia.upf.edu/models.html#\n",
    "\n",
    "- Audio Event Recognition\n",
    "- Music Style Classification\n",
    "- Music Auto Tagging\n",
    "- Transfer learning Classifiers\n",
    "- Feature Extractors\n",
    "- Pitch Detection\n",
    "- Source Seperation\n",
    "- Tempo Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e57466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from essentia.standard import TensorflowPredictMusiCNN\n",
    "import json\n",
    "\n",
    "with open('../Models/msd-musicnn-1.json', 'r') as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f38b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../AudioFiles/DontStop.mp3'\n",
    "model = '../Models/msd-musicnn-1.pb'\n",
    "\n",
    "audio = es.MonoLoader(filename=file, sampleRate=16000)()\n",
    "model = TensorflowPredictMusiCNN(graphFilename=model)\n",
    "activations = model(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f2986",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(activations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d948a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.matshow(activations.T, aspect='auto')\n",
    "\n",
    "ax.set_yticks(range(len(metadata['classes'])))\n",
    "ax.set_yticklabels(metadata['classes'])\n",
    "ax.set_xlabel('patch number')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.title('Activations')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = '../Models/gender-musicnn-msd-2.pb'\n",
    "\n",
    "audio = es.MonoLoader(filename=file, sampleRate=16000)()\n",
    "model = TensorflowPredictMusiCNN(graphFilename=modelPath)\n",
    "activations_gender = model(audio)\n",
    "\n",
    "plot(activations_gender)\n",
    "for label, probability in zip(['female', 'male'], activations_gender.mean(axis=0)):\n",
    "    print(f'{label}: {100 * probability:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from essentia.standard import MonoLoader, TensorflowPredictVGGish\n",
    "\n",
    "activations_dance = TensorflowPredictVGGish(graphFilename='../Models/danceability-vggish.pb')(audio)\n",
    "\n",
    "plot(activations_dance)\n",
    "for label, probability in zip(['danceable', 'not_danceable'], activations_dance.mean(axis=0)):\n",
    "    print(f'{label}: {100 * probability:.1f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "356fe98d",
   "metadata": {},
   "source": [
    "#### Spleeter \n",
    "- https://spleeter.online/\n",
    "- https://essentia.upf.edu/models.html#music-style-classification\n",
    "- --> bis zu 5 Instrumentengruppen separieren\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e740c235",
   "metadata": {},
   "source": [
    "### Streaming Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia.streaming as ess\n",
    "\n",
    "file = '../AudioFiles/DontStop.mp3'\n",
    "\n",
    "# instantiate\n",
    "loader = ess.MonoLoader(filename = file)\n",
    "frameCutter = ess.FrameCutter(frameSize = 1024, hopSize = 512)\n",
    "w = ess.Windowing(type = 'hann')\n",
    "spec = ess.Spectrum()\n",
    "mfcc = ess.MFCC()\n",
    "centroid = ess.Centroid(range=22050)\n",
    "rolloff = ess.RollOff()\n",
    "\n",
    "# connect algorithms\n",
    "loader.audio >> frameCutter.signal\n",
    "frameCutter.frame >> w.frame >> spec.frame\n",
    "spec.spectrum >> mfcc.spectrum\n",
    "spec.spectrum >> centroid.array\n",
    "spec.spectrum >> rolloff.spectrum\n",
    "\n",
    "# connect to Pool\n",
    "mfcc.bands >> None\n",
    "mfcc.mfcc >> (pool, 'lowlevel.mfcc')\n",
    "centroid.centroid >> (pool, 'lowlevel.centroid')\n",
    "rolloff.rollOff >> (pool, 'lowlevel.rolloff')\n",
    "\n",
    "# run network\n",
    "essentia.run(loader)\n",
    "print(pool['lowlevel.rolloff'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63cd3935",
   "metadata": {},
   "source": [
    "### Essentia real-time pitch tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497dcb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundcard as sc\n",
    "from collections import Counter\n",
    "\n",
    "hopSize = 128\n",
    "frameSize = 2048\n",
    "sampleRate = 44100\n",
    "buffer_size = frameSize * 4\n",
    "\n",
    "# instantiate algorithms\n",
    "mics = sc.all_microphones()\n",
    "buffer = np.zeros(buffer_size, dtype='float32')\n",
    "vimp = ess.VectorInput(buffer)\n",
    "pitch = ess.PredominantPitchMelodia(guessUnvoiced=False,frameSize=frameSize,hopSize=hopSize, sampleRate=sampleRate)\n",
    "pitchMel = ess.MultiPitchMelodia(frameSize=frameSize,hopSize=hopSize, sampleRate=sampleRate)\n",
    "filter = ess.PitchFilter(useAbsolutePitchConfidence=False)\n",
    "pool = essentia.Pool()\n",
    "\n",
    "# connect algorithms\n",
    "vimp.data   >> pitch.signal\n",
    "pitch.pitch >> filter.pitch\n",
    "pitch.pitchConfidence >> filter.pitchConfidence\n",
    "pitch.pitch    >> (pool, 'pitch')\n",
    "pitch.pitchConfidence  >> (pool, 'confidence')\n",
    "filter.pitchFiltered >> (pool, 'filterPitch')\n",
    "\n",
    "def process(data):\n",
    "    buffer[:] = data.flatten()\n",
    "    essentia.reset(vimp)\n",
    "    essentia.run(vimp)\n",
    "\n",
    "    confidence = np.mean(list(pool['confidence']))\n",
    "    if confidence > 0.0001:\n",
    "        pitch = np.array(list(pool['filterPitch']))\n",
    "        pitch = pitch[pitch != float(0)]\n",
    "        b = Counter(np.around(np.array(pitch), 1))\n",
    "        print(b)\n",
    "        pool.clear()\n",
    "\n",
    "# capture microphone input\n",
    "with sc.all_microphones()[1].recorder(samplerate=sampleRate) as mic:\n",
    "    while True:\n",
    "        process(mic.record(numframes=buffer_size).mean(axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "344b92fd",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4eaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from essentia.standard import *\n",
    "x = np.arange(len(audio))\n",
    "y = np.sin(2 * np.pi * 8 *  x / sr)\n",
    "\n",
    "audio_sine = audio * y\n",
    "sf.write('../AudioFiles/sine.wav', audio_sine, samplerate=sr)\n",
    "IPython.display.Audio('../AudioFiles/sine.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba99652",
   "metadata": {},
   "outputs": [],
   "source": [
    "random = np.random.rand(len(audio),1).T.astype('f')\n",
    "\n",
    "audio_rand = audio + random[0] * 0.1\n",
    "sf.write('../AudioFiles/1_Random.wav', audio_rand, samplerate=sr)\n",
    "IPython.display.Audio('../AudioFiles/1_Random.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7fe578",
   "metadata": {},
   "outputs": [],
   "source": [
    "addNoise = NoiseAdder(level= -25)(audio)\n",
    "sf.write('../AudioFiles/1_Random.wav', addNoise, samplerate=sr)\n",
    "IPython.display.Audio('../AudioFiles/1_Random.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpf = HighPass(cutoffFrequency=600)(audio)\n",
    "sf.write('../AudioFiles/highpass.wav', hpf, samplerate=sr)\n",
    "IPython.display.Audio('../AudioFiles/highpass.wav')\n",
    "\n",
    "# LowPass, Bandpass, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b33778",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_fast = librosa.effects.time_stretch(audio, rate=0.5)\n",
    "sf.write('../AudioFiles/Resample.wav', audio_fast, samplerate=sr)\n",
    "IPython.display.Audio('../AudioFiles/Resample.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d55865",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pitch = librosa.effects.pitch_shift(audio, sr=sr, n_steps = 4)\n",
    "sf.write('../AudioFiles/pitch.wav', audio_pitch, samplerate=sr)\n",
    "IPython.display.Audio('../AudioFiles/pitch.wav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ceb75c1",
   "metadata": {},
   "source": [
    "##### Pytorch Data Augmentation\n",
    "\n",
    "- https://pypi.org/project/torchaudio-augmentations/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b46c9541",
   "metadata": {},
   "source": [
    "### Working with features - Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86451846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "d_path = '/Users/maed/Documents/Projects/MIR/MIR_Tutorials/EssentiaTutorials/MIR_Tutorial/Sonstiges/HSD_Rec_2500_Dimensions_Genre.csv'\n",
    "df = pd.read_csv(d_path)\n",
    "df = df.drop(index = [131, 294, 295, 296, 297, 298, 299])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5a43db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-SNE\n",
    "non_numeric = ['Unnamed: 0', 'Track']\n",
    "\n",
    "# drop non numeric and zscore\n",
    "df_numeric = df.drop(non_numeric, axis=1)\n",
    "df_z = zscore(df_numeric)\n",
    "m = TSNE(learning_rate = 50, n_components = 3)\n",
    "tsne_features = m.fit_transform(df_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D T-SNE\n",
    "df['x'] = tsne_features[:,0]\n",
    "df['y'] = tsne_features[:,1]\n",
    "plt = sns.scatterplot(x= 'x', y = 'y', hue=df['voice'], data=df)\n",
    "plt.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b17d9254",
   "metadata": {},
   "source": [
    "### Weitere Tools, Libraries, ... \n",
    "\n",
    "MIR Related:\n",
    "- https://ismir.net/resources/datasets/\n",
    "- https://www.audiolabs-erlangen.de/resources/MIR/FMP/C0/C0.html\n",
    "- https://ismir.net/resources/software-tools/\n",
    "- https://github.com/jordipons/musicnn-training\n",
    "- https://music-classification.github.io/tutorial/landing-page.html\n",
    "- https://developer.spotify.com/documentation/web-api\n",
    "- https://www.youtube.com/@ValerioVelardoTheSoundofAI\n",
    "- https://mtg.github.io/essentia-labs/news/tensorflow/2023/02/08/fsdsinet-models/\n",
    "- https://essentia.upf.edu/api/docs/\n",
    "\n",
    "Audio Synthese/Programming Tools:\n",
    "- https://juce.com/\n",
    "- https://puredata.info/\n",
    "- https://supercollider.github.io/\n",
    "- https://cycling74.com/\n",
    "- https://csound.com/\n",
    "\n",
    "Hardware Stuff:\n",
    "- https://blokas.io/pisound/\n",
    "- https://bela.io/\n",
    "\n",
    "Also nice:\n",
    "- https://openframeworks.cc/ --> hat auch Essentia AddOn\n",
    "- https://derivative.ca/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
